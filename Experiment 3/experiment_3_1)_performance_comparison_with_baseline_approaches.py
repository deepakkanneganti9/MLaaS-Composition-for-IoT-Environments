# -*- coding: utf-8 -*-
"""Experiment 3 : 1) Performance Comparison with Baseline Approaches.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kK5p4vBND2oczBCp_XWUUw7zbFkgRzIH

**MLaaS Composability Model**
---
"""

# ===========================
# CELL 1 — READ 3 COMBO CSVs + COMPUTE MCS FOR EACH
# ===========================
import os, ast
import pandas as pd
import numpy as np
from google.colab import drive

drive.mount('/content/drive')

# =====================================================
# INPUTS
# =====================================================
PROFILES_PATH = "/content/CIFAR10_Client_Profiles_For_Composability_100.csv"

# ✅ Read multiple combo files (3 files like your image)
COMBO_FILES = {
    "A_2": "/content/All_Combinations_2_CIFAR_100_4050.csv",
    "B_3": "/content/All_Combinations_3_CIFAR_32_4960.csv",
    "C_5": "/content/All_Combinations_5_CIFAR_16_4368.csv",
}

# ✅ Output per file (so next cell can use them)
OUT_PATHS = {
    k: f"/content/{k}_WITH_MCS.csv" for k in COMBO_FILES.keys()
}

df_profiles = pd.read_csv(PROFILES_PATH)

# =====================================================
# CONFIG
# =====================================================
THRESHOLD_MCS = 0.85

WEIGHTS = {
    "DHS": 0.99,
    "MUS": 0.95,
    "SHS": 0.45,
    "SES": 0.60,
    "HSQ": 0.78,
    "SRS": 0.32,
}

WEIGHTS_DIR = "/content/drive/MyDrive/MLaaS_Weights_30_FMNIST"

# SES (LATENCY ONLY)
SES_T_DEFAULT = 3676.331401
SES_ALPHA_DEFAULT = 1.0

# =====================================================
# HELPERS
# =====================================================
def make_combination_string(row, client_cols):
    ids = []
    for c in client_cols:
        if pd.notna(row[c]):
            ids.append(str(int(row[c])))
    return "_".join(ids)

def _cosine_sim(a, b, eps=1e-12):
    a = np.asarray(a, dtype=np.float64)
    b = np.asarray(b, dtype=np.float64)
    na, nb = np.linalg.norm(a), np.linalg.norm(b)
    if na < eps or nb < eps:
        return 0.0
    return float(np.dot(a, b) / (na * nb))

def _clip01(x):
    if x is None or not np.isfinite(x):
        return np.nan
    return float(np.clip(x, 0.0, 1.0))

def _to_quality_vector(x):
    try:
        return np.asarray(ast.literal_eval(x), dtype=np.float64)
    except Exception:
        return None

# =====================================================
# GROUP-LEVEL RULES
# =====================================================
def compute_dhs_group(client_profiles):
    label_cols = [c for c in client_profiles.columns if c.startswith("Label")]
    dists = client_profiles[label_cols].to_numpy(dtype=np.float64)
    terms = []
    for d in dists:
        if d.sum() > 0:
            terms.append((d.max() - d.min()) / d.sum())
    return 1.0 - np.mean(terms) if terms else 0.0

def compute_shs_group(client_profiles, alpha=0.5, beta=0.5, eps=1e-12):
    cp = client_profiles["C_p"].astype(float).to_numpy()
    bw = client_profiles["BW"].astype(float).to_numpy()
    if cp.size == 0 or bw.size == 0:
        return 1.0

    cp_min, cp_max = np.min(cp), np.max(cp)
    bw_min, bw_max = np.min(bw), np.max(bw)

    cp_scaled = np.ones_like(cp, dtype=np.float64) if abs(cp_max - cp_min) < eps else (cp - cp_min) / (cp_max - cp_min)
    bw_scaled = np.ones_like(bw, dtype=np.float64) if abs(bw_max - bw_min) < eps else (bw - bw_min) / (bw_max - bw_min)

    mu_cp = cp_scaled.mean()
    mu_bw = bw_scaled.mean()

    dev = alpha * np.abs(cp_scaled - mu_cp) + beta * np.abs(bw_scaled - mu_bw)
    shs = 1.0 - dev.mean()
    return float(np.clip(shs, 0.0, 1.0))

def compute_ses_group(client_profiles, T, alpha=1.0):
    latencies = client_profiles["Latency(ms)"].astype(float).to_numpy()
    if latencies.size == 0:
        return 1.0
    mean_latency = latencies.mean()
    if mean_latency <= T:
        return 1.0
    return float((T / mean_latency) ** alpha)

def compute_hsq_group(client_profiles):
    vecs = []
    for q in client_profiles["Quality_Factor"].values:
        v = _to_quality_vector(q)
        if v is not None:
            vecs.append(v)
    if not vecs:
        return 0.0
    L = min(len(v) for v in vecs)
    vecs = [v[:L] for v in vecs]
    mu = np.mean(np.vstack(vecs), axis=0)
    return np.mean([_cosine_sim(v, mu) for v in vecs])

def compute_srs_group(client_profiles):
    r = client_profiles["Reliability_Score"].astype(float).to_numpy()
    mu = r.mean()
    return 1.0 - np.mean(np.abs(r - mu))

# =====================================================
# MUS (weights vectors)
# =====================================================
_VEC_CACHE = {}

def _client_weight_path(cid):
    return os.path.join(WEIGHTS_DIR, f"client_{int(cid)}_local.npz")

def _npz_to_vec(path):
    if path in _VEC_CACHE:
        return _VEC_CACHE[path]
    if not os.path.exists(path):
        _VEC_CACHE[path] = np.asarray([])
        return _VEC_CACHE[path]
    data = np.load(path)
    vec = np.concatenate([data[k].ravel() for k in data.files])
    _VEC_CACHE[path] = vec
    return vec

def compute_mus_for_client_ids(client_ids):
    vecs = []
    for cid in client_ids:
        v = _npz_to_vec(_client_weight_path(cid))
        if v.size > 0:
            vecs.append(v)
    if not vecs:
        return np.nan
    L = min(len(v) for v in vecs)
    vecs = [v[:L] for v in vecs]
    mu = np.mean(np.vstack(vecs), axis=0)
    sims = [_cosine_sim(v, mu) for v in vecs]
    return (np.mean(sims) + 1.0) / 2.0

# =====================================================
# RUN FOR EACH FILE
# =====================================================
df_outs = {}  # <- store all outputs here for Cell 2

for tag, path in COMBO_FILES.items():
    print(f"\n===== Processing: {tag} =====")
    df_combos = pd.read_csv(path)

    client_cols = [c for c in df_combos.columns if c.startswith("Client_")]
    if not client_cols:
        raise ValueError(f"{tag}: No Client_* columns found in {path}")

    df_combos["Combination"] = df_combos.apply(lambda r: make_combination_string(r, client_cols), axis=1)
    df_combos["Num_Clients"] = df_combos[client_cols].notna().sum(axis=1)

    records = []
    for _, row in df_combos.iterrows():
        client_ids = [row[c] for c in client_cols if pd.notna(row[c])]
        prof = df_profiles[df_profiles["Client_ID"].isin(client_ids)]
        if prof.empty:
            continue

        DHS = _clip01(compute_dhs_group(prof))
        SHS = _clip01(compute_shs_group(prof))
        SES = _clip01(compute_ses_group(prof, T=SES_T_DEFAULT, alpha=SES_ALPHA_DEFAULT))
        HSQ = _clip01(compute_hsq_group(prof))
        SRS = _clip01(compute_srs_group(prof))
        MUS = _clip01(compute_mus_for_client_ids(client_ids))

        num, den = 0.0, 0.0
        for k, v in [("DHS",DHS),("SHS",SHS),("SES",SES),("HSQ",HSQ),("SRS",SRS),("MUS",MUS)]:
            if np.isfinite(v):
                num += WEIGHTS[k] * v
                den += WEIGHTS[k]

        mcs_raw = num / den if den > 0 else np.nan
        MCS = _clip01(mcs_raw)

        records.append({
            "Combination": row["Combination"],
            "Num_Clients": int(len(client_ids)),
            "DHS": DHS, "SHS": SHS, "SES": SES, "HSQ": HSQ, "SRS": SRS, "MUS": MUS,
            "MCS": MCS,
            "Is_Composable_MCS": int(MCS > THRESHOLD_MCS),
        })

    df_rules = pd.DataFrame(records)
    df_out = df_combos.merge(df_rules, on=["Combination","Num_Clients"], how="left")
    df_out = df_out.sort_values("MCS", ascending=False).reset_index(drop=True)

    df_out.to_csv(OUT_PATHS[tag], index=False)
    print(f"✅ Saved: {OUT_PATHS[tag]} | Rows: {len(df_out)}")

    df_outs[tag] = df_out

# df_outs["C_5"]  # example access

df=pd.read_csv("/content/A_2_WITH_MCS.csv")
df.columns

df[['Global_Accuracy','MCS']].describe()

"""**FMNIST**

"""

# ===========================
# CELL 2 — CONFUSION MATRICES (1x3 SIDE-BY-SIDE) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt
import numpy as np
# --------------------------------------------------
# Per-file thresholds (set here once)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 83, "mcs": 0.88},
    "B_3": {"acc": 73, "mcs": 0.83},
    "C_5": {"acc": 73, "mcs": 0.83},
}

# --------------------------------------------------
# PLOT 1x3 CONFUSION MATRICES
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    df_eval = df_outs[tag].copy()

    ACC_TH = THRESHOLDS[tag]["acc"]
    MCS_TH = THRESHOLDS[tag]["mcs"]

    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in df_out. Check your combos CSV columns.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["MCS"] > MCS_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    # heatmap style (matplotlib only)
    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, MCS>{MCS_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (MCS)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# OPTIONAL: PRINT REPORTS (one by one)
# --------------------------------------------------
for tag in tags:
    df_eval = df_outs[tag].copy()
    ACC_TH = THRESHOLDS[tag]["acc"]
    MCS_TH = THRESHOLDS[tag]["mcs"]

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["MCS"] > MCS_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))

"""**MINIST**

"""

# ===========================
# CELL 2 — CONFUSION MATRICES (1x3 SIDE-BY-SIDE) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt
import numpy as np
# --------------------------------------------------
# Per-file thresholds (set here once)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 87, "mcs": 0.88},
    "B_3": {"acc": 82, "mcs": 0.85},
    "C_5": {"acc": 81, "mcs": 0.82},
}
# --------------------------------------------------
# PLOT 1x3 CONFUSION MATRICES
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    df_eval = df_outs[tag].copy()

    ACC_TH = THRESHOLDS[tag]["acc"]
    MCS_TH = THRESHOLDS[tag]["mcs"]

    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in df_out. Check your combos CSV columns.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["MCS"] > MCS_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    # heatmap style (matplotlib only)
    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, MCS>{MCS_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (MCS)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# OPTIONAL: PRINT REPORTS (one by one)
# --------------------------------------------------
for tag in tags:
    df_eval = df_outs[tag].copy()
    ACC_TH = THRESHOLDS[tag]["acc"]
    MCS_TH = THRESHOLDS[tag]["mcs"]

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["MCS"] > MCS_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))

import os
import ast
import pandas as pd
import numpy as np
from google.colab import drive

drive.mount('/content/drive')

# =====================================================
# INPUT FILES (ONLY THESE TWO MATTER)
# =====================================================
COMBOS_PATH   = "/content/All_Combinations_5_MNIST_16_4368.csv"
PROFILES_PATH = "/content/MNIST_Client_Profiles_For_Composability_100.csv"
OUT_PATH      = "/content/combination_2_WITH_COMPOSABILITY_SCORES.csv"

df_combos   = pd.read_csv(COMBOS_PATH)
df_profiles = pd.read_csv(PROFILES_PATH)

# Works for any n (2/3/5/7/9/10/...)
client_cols = [c for c in df_combos.columns if c.startswith("Client_")]

# =====================================================
# CONFIG
# =====================================================
THRESHOLD_MCS = 0.85

WEIGHTS = {
    "DHS": 0.99,
    "MUS": 0.95,
    "SHS": 0.45,
    "SES": 0.60,
    "HSQ": 0.78,
    "SRS": 0.32,
}

WEIGHTS_DIR = "/content/drive/MyDrive/MLaaS_Weights_20_MNIST"



# SES CONFIG (LATENCY-ONLY)
SES_T_DEFAULT = 3676.331401
SES_ALPHA_DEFAULT = 1.0

# =====================================================
# HELPERS
# =====================================================
def make_combination_string(row, client_cols):
    ids = []
    for c in client_cols:
        if pd.notna(row[c]):
            ids.append(str(int(row[c])))
    return "_".join(ids)

def _cosine_sim(a, b, eps=1e-12):
    a = np.asarray(a, dtype=np.float64)
    b = np.asarray(b, dtype=np.float64)
    na, nb = np.linalg.norm(a), np.linalg.norm(b)
    if na < eps or nb < eps:
        return 0.0
    return float(np.dot(a, b) / (na * nb))

def _clip01(x):
    if x is None or not np.isfinite(x):
        return np.nan
    return float(np.clip(x, 0.0, 1.0))

# =====================================================
# GROUP-LEVEL RULES
# =====================================================
def compute_dhs_group(client_profiles):
    label_cols = [c for c in client_profiles.columns if c.startswith("Label")]
    dists = client_profiles[label_cols].to_numpy(dtype=np.float64)
    terms = []
    for d in dists:
        if d.sum() > 0:
            terms.append((d.max() - d.min()) / d.sum())
    return 1.0 - np.mean(terms) if terms else 0.0

def compute_shs_group(client_profiles, alpha=0.5, beta=0.5, eps=1e-12):
    """
    Service Heterogeneity Score (SHS) using Computation Power (C_p) and Bandwidth (BW).

    Steps:
    1) Take C_p and BW from client_profiles
    2) Min-max scale each within the group to [0,1]
    3) Compute group means (mu_cp, mu_bw)
    4) Compute weighted mean absolute deviation from means
    5) Convert to score: SHS = 1 - mean_deviation
    """

    cp = client_profiles["C_p"].astype(float).to_numpy()
    bw = client_profiles["BW"].astype(float).to_numpy()

    if cp.size == 0 or bw.size == 0:
        return 1.0  # no heterogeneity if no clients

    # -----------------------------
    # Min-max scaling to [0,1]
    # -----------------------------
    cp_min, cp_max = np.min(cp), np.max(cp)
    bw_min, bw_max = np.min(bw), np.max(bw)

    if abs(cp_max - cp_min) < eps:
        cp_scaled = np.ones_like(cp, dtype=np.float64)  # all identical => no variation
    else:
        cp_scaled = (cp - cp_min) / (cp_max - cp_min)

    if abs(bw_max - bw_min) < eps:
        bw_scaled = np.ones_like(bw, dtype=np.float64)
    else:
        bw_scaled = (bw - bw_min) / (bw_max - bw_min)

    # -----------------------------
    # Mean + deviation
    # -----------------------------
    mu_cp = cp_scaled.mean()
    mu_bw = bw_scaled.mean()

    dev = alpha * np.abs(cp_scaled - mu_cp) + beta * np.abs(bw_scaled - mu_bw)

    # Higher score = more homogeneous (less heterogeneity)
    shs = 1.0 - dev.mean()

    return float(np.clip(shs, 0.0, 1.0))

# =====================================================
# ✅ FIXED SES (LATENCY ONLY)
# =====================================================
def compute_ses_group(client_profiles, T, alpha=1.0):
    latencies = client_profiles["Latency(ms)"].astype(float).to_numpy()
    if latencies.size == 0:
        return 1.0
    mean_latency = latencies.mean()
    if mean_latency <= T:
        return 1.0
    return float((T / mean_latency) ** alpha)

def _to_quality_vector(x):
    try:
        return np.asarray(ast.literal_eval(x), dtype=np.float64)
    except Exception:
        return None

def compute_hsq_group(client_profiles):
    vecs = []
    for q in client_profiles["Quality_Factor"].values:
        v = _to_quality_vector(q)
        if v is not None:
            vecs.append(v)
    if not vecs:
        return 0.0
    L = min(len(v) for v in vecs)
    vecs = [v[:L] for v in vecs]
    mu = np.mean(np.vstack(vecs), axis=0)
    return np.mean([_cosine_sim(v, mu) for v in vecs])

def compute_srs_group(client_profiles):
    r = client_profiles["Reliability_Score"].astype(float).to_numpy()
    mu = r.mean()
    return 1.0 - np.mean(np.abs(r - mu))

# =====================================================
# MUS
# =====================================================
_VEC_CACHE = {}

def _client_weight_path(cid):
    return os.path.join(WEIGHTS_DIR, f"client_{int(cid)}_local.npz")

def _npz_to_vec(path):
    if path in _VEC_CACHE:
        return _VEC_CACHE[path]
    if not os.path.exists(path):
        _VEC_CACHE[path] = np.asarray([])
        return _VEC_CACHE[path]
    data = np.load(path)
    vec = np.concatenate([data[k].ravel() for k in data.files])
    _VEC_CACHE[path] = vec
    return vec

def compute_mus_for_client_ids(client_ids):
    vecs = []
    for cid in client_ids:
        v = _npz_to_vec(_client_weight_path(cid))
        if v.size > 0:
            vecs.append(v)
    if not vecs:
        return np.nan
    L = min(len(v) for v in vecs)
    vecs = [v[:L] for v in vecs]
    mu = np.mean(np.vstack(vecs), axis=0)
    sims = [_cosine_sim(v, mu) for v in vecs]
    return (np.mean(sims) + 1.0) / 2.0

# =====================================================
# BUILD COMBINATIONS
# =====================================================
df_combos["Combination"] = df_combos.apply(
    lambda r: make_combination_string(r, client_cols), axis=1
)
df_combos["Num_Clients"] = df_combos[client_cols].notna().sum(axis=1)

# =====================================================
# COMPUTE RULES + MCS
# =====================================================
records = []

for _, row in df_combos.iterrows():
    client_ids = [row[c] for c in client_cols if pd.notna(row[c])]
    prof = df_profiles[df_profiles["Client_ID"].isin(client_ids)]
    if prof.empty:
        continue

    DHS = _clip01(compute_dhs_group(prof))
    SHS = _clip01(compute_shs_group(prof))
    SES = _clip01(compute_ses_group(
        prof, T=SES_T_DEFAULT, alpha=SES_ALPHA_DEFAULT
    ))
    HSQ = _clip01(compute_hsq_group(prof))
    SRS = _clip01(compute_srs_group(prof))
    MUS = _clip01(compute_mus_for_client_ids(client_ids))

    num, den = 0.0, 0.0
    for k, v in [("DHS",DHS),("SHS",SHS),("SES",SES),
                 ("HSQ",HSQ),("SRS",SRS),("MUS",MUS)]:
        if np.isfinite(v):
            num += WEIGHTS[k] * v
            den += WEIGHTS[k]

    MCS = num / den if den > 0 else np.nan

    records.append({
        "Combination": row["Combination"],
        "Num_Clients": len(client_ids),
        "DHS": DHS,
        "SHS": SHS,
        "SES": SES,
        "HSQ": HSQ,
        "SRS": SRS,
        "MUS": MUS,
        "MCS": _clip01(MCS),
        "Is_Composable_MCS": int(MCS > THRESHOLD_MCS),
    })
df_rules = pd.DataFrame(records)
df_out = df_combos.merge(df_rules, on=["Combination","Num_Clients"], how="left")
df_out = df_out.sort_values("MCS", ascending=False).reset_index(drop=True)
df_out.to_csv(OUT_PATH, index=False)
print(f"✅ Saved: {OUT_PATH}")
df_out

df_out[["Global_Accuracy","MCS"]]

df_out[["Global_Accuracy","MCS"]].describe()

from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# df_out must contain: Global_Accuracy, MCS  (as in your screenshot)
df_eval = df_out.copy()

# ------------------------------
# THRESHOLD1 (EDIT IF NEEDED)
# ------------------------------
ACC_TH = 81
MCS_TH = 0.82

# ------------------------------
# TRUE vs PRED (FROM IMAGE COLS)
# ------------------------------
y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)   # ground truth
y_pred = (df_eval["MCS"] > MCS_TH).astype(int)               # predicted

# ------------------------------
# METRICS
# ------------------------------
conf_matrix = confusion_matrix(y_true, y_pred)
accuracy = accuracy_score(y_true, y_pred)
report = classification_report(y_true, y_pred, digits=4)

print("========== CONFUSION MATRIX ==========")
print(conf_matrix)

print("\n========== CLASSIFICATION REPORT ==========")
print(report)

print("\n========== ACCURACY ==========")
print("Accuracy:", round(accuracy, 4))

# ------------------------------
# HEATMAP (NO SEABORN)
# ------------------------------
plt.figure(figsize=(6, 4))
plt.imshow(conf_matrix, interpolation="nearest")
plt.title("Confusion Matrix (Global_Accuracy vs MCS)")
plt.xlabel("Predicted Class (MCS)")
plt.ylabel("True Class (Accuracy)")
plt.xticks([0, 1], ["Not Composable", "Composable"])
plt.yticks([0, 1], ["Not Composable", "Composable"])

for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        plt.text(j, i, str(conf_matrix[i, j]), ha="center", va="center")

plt.colorbar()
plt.tight_layout()
plt.show()

"""**FedCS**
---
"""

# ===========================
# CELL 1 — Fed-SF for MULTIPLE COMBO CSV FILES (2/3/5) + SAVE RESULTS
# ===========================
import pandas as pd

# ======================================================
# INPUTS
# ======================================================
PROFILES_PATH = "/content/CIFAR10_Client_Profiles_For_Composability_100.csv"

COMBO_FILES = {
    "A_2": "/content/All_Combinations_2_CIFAR_100_4050.csv",
    "B_3": "/content/All_Combinations_3_CIFAR_32_4960.csv",
    "C_5": "/content/All_Combinations_5_CIFAR_16_4368.csv",
}

OUT_PATHS = {k: f"/content/{k}_FedSF_results.csv" for k in COMBO_FILES.keys()}

# ======================================================
# LOAD CLIENT PROFILES ONCE
# ======================================================
df_clients = pd.read_csv(PROFILES_PATH)

# ======================================================
# HELPERS
# ======================================================
def ensure_combination_column(df_base: pd.DataFrame, prefix="Client_") -> pd.DataFrame:
    if "Combination" in df_base.columns:
        return df_base

    client_cols = [c for c in df_base.columns if c.startswith(prefix)]
    if not client_cols:
        raise ValueError(
            "Cannot build 'Combination'. Expected either an existing 'Combination' column "
            "or columns like Client_1, Client_2, ..., Client_k."
        )

    def col_key(name: str) -> int:
        tail = name.split("_")[-1]
        return int(tail) if tail.isdigit() else 10**9

    client_cols = sorted(client_cols, key=col_key)

    def row_to_combo(row) -> str:
        vals = []
        for c in client_cols:
            v = row[c]
            if pd.isna(v):
                continue
            vals.append(str(int(v)))
        return "_".join(vals)

    df_base["Combination"] = df_base.apply(row_to_combo, axis=1)
    return df_base

def compute_delta(row, theta):
    tD = row["Train_Time(s)"]          # seconds
    tL = row["Latency(ms)"] / 1000.0   # ms -> seconds
    return tL + max(0.0, tD - theta)

# ======================================================
# CONFIG
# ======================================================
THRESHOLD_TIME = 32.0  # Fed-SF time threshold (same logic)

# ======================================================
# RUN Fed-SF FOR EACH COMBO FILE
# ======================================================
fed_sf_outputs = {}  # keep in memory for Cell 2

for tag, combos_path in COMBO_FILES.items():
    print(f"\n===== Fed-SF Processing: {tag} =====")

    df_base = pd.read_csv(combos_path)
    df_base = ensure_combination_column(df_base)

    results = []
    for combo_str in df_base["Combination"]:
        combo = list(map(int, combo_str.split("_")))

        theta = 0.0
        combo_rows = df_clients[df_clients["Client_ID"].isin(combo)].copy()
        combo_rows = combo_rows.sort_values("Train_Time(s)")

        for _, row in combo_rows.iterrows():
            theta += compute_delta(row, theta)

        raw_score = 1.0 - (theta / THRESHOLD_TIME)

        results.append({
            "Combination": combo_str,
            "Delta_Sum": round(theta, 3),
            "Score": raw_score,   # raw for now
        })

    df_results = pd.DataFrame(results)

    # ----------------------------
    # SCALE Score to [0,1] (overwrite Score)
    # ----------------------------
    smin = df_results["Score"].min()
    smax = df_results["Score"].max()
    if smax > smin:
        df_results["Score"] = (df_results["Score"] - smin) / (smax - smin)
    else:
        df_results["Score"] = 1.0
    df_results["Score"] = df_results["Score"].round(6)

    # Save + keep
    df_results.to_csv(OUT_PATHS[tag], index=False)
    print(f"✅ Saved: {OUT_PATHS[tag]} | Rows: {len(df_results)}")
    print("Scaled Score min/max:", float(df_results["Score"].min()), float(df_results["Score"].max()))

    fed_sf_outputs[tag] = df_results

df=pd.read_csv("/content/C_5_FedSF_results.csv")
df['Score'].describe()

"""**CIFAR**

"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once here)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 49, "fed_sf": 0.69},
    "B_3": {"acc": 49, "fed_sf": 0.66},
    "C_5": {"acc": 49, "fed_sf": 0.65},
}

# --------------------------------------------------
# Load the SAME combo files again to get Global_Accuracy
# and merge with Fed-SF by Combination (NOT row-wise)
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_sf_outputs[tag].copy()

    # Merge to align scores correctly
    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedSF_Score"})

    # Column check (change here if your file uses a different name)
    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. موجود؟ check column name exactly.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, FedSF>{FED_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (FedSF)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_eval = combo_dfs[tag].merge(
        fed_sf_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedSF_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))



"""**HAR**

"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once here)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 83, "fed_sf": 0.60},
    "B_3": {"acc": 73, "fed_sf": 0.60},
    "C_5": {"acc": 73, "fed_sf": 0.65},
}

# --------------------------------------------------
# Load the SAME combo files again to get Global_Accuracy
# and merge with Fed-SF by Combination (NOT row-wise)
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_sf_outputs[tag].copy()

    # Merge to align scores correctly
    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedSF_Score"})

    # Column check (change here if your file uses a different name)
    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. موجود؟ check column name exactly.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, FedSF>{FED_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (FedSF)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_eval = combo_dfs[tag].merge(
        fed_sf_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedSF_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))



"""**FMNIST**"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once here)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 83, "fed_sf": 0.65},
    "B_3": {"acc": 73, "fed_sf": 0.65},
    "C_5": {"acc": 73, "fed_sf": 0.65},
}

# --------------------------------------------------
# Load the SAME combo files again to get Global_Accuracy
# and merge with Fed-SF by Combination (NOT row-wise)
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_sf_outputs[tag].copy()

    # Merge to align scores correctly
    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedSF_Score"})

    # Column check (change here if your file uses a different name)
    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. موجود؟ check column name exactly.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, FedSF>{FED_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (FedSF)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_eval = combo_dfs[tag].merge(
        fed_sf_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedSF_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))



"""**MNIST**


"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once here)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 80, "fed_sf": 0.80},
    "B_3": {"acc": 80, "fed_sf": 0.80},
    "C_5": {"acc": 79, "fed_sf": 0.79},
}

# --------------------------------------------------
# Load the SAME combo files again to get Global_Accuracy
# and merge with Fed-SF by Combination (NOT row-wise)
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_sf_outputs[tag].copy()

    # Merge to align scores correctly
    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedSF_Score"})

    # Column check (change here if your file uses a different name)
    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. موجود؟ check column name exactly.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, FedSF>{FED_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (FedSF)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_eval = combo_dfs[tag].merge(
        fed_sf_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedSF_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))



"""**FedMCCS**
---
"""

# ===========================
# CELL 1 — Fed-MCCS for MULTIPLE COMBO CSV FILES (2/3/5) + SCALE SCORE + SAVE
# ===========================
import pandas as pd
from sklearn.linear_model import LinearRegression

# --------------------------------------------------
# INPUTS
# --------------------------------------------------
PROFILES_PATH = "/content/HAR_Client_Profiles_For_Composability_100.csv"

COMBO_FILES = {
    "A_2": "/content/All_Combinations_2_HAR_100_4050.csv",
    "B_3": "/content/All_Combinations_3_HAR_32_4960.csv",
    "C_5": "/content/All_Combinations_5_HAR_16_4368.csv",
}

OUT_PATHS = {k: f"/content/{k}_FedMCCS_results.csv" for k in COMBO_FILES.keys()}

# --------------------------------------------------
# LOAD CLIENT PROFILES ONCE
# --------------------------------------------------
df_clients = pd.read_csv(PROFILES_PATH)

# ======================================================
# ENSURE "Combination" COLUMN EXISTS
# ======================================================
def ensure_combination_column(df_base: pd.DataFrame, prefix="Client_") -> pd.DataFrame:
    if "Combination" in df_base.columns:
        return df_base

    client_cols = [c for c in df_base.columns if c.startswith(prefix)]
    if not client_cols:
        raise ValueError(
            "Cannot build 'Combination'. Expected either an existing 'Combination' column "
            "or columns like Client_1, Client_2, ..., Client_k."
        )

    def col_key(name: str) -> int:
        tail = name.split("_")[-1]
        return int(tail) if tail.isdigit() else 10**9

    client_cols = sorted(client_cols, key=col_key)

    def row_to_combo(row) -> str:
        vals = []
        for c in client_cols:
            v = row[c]
            if pd.isna(v):
                continue
            vals.append(str(int(v)))
        return "_".join(vals)

    df_base["Combination"] = df_base.apply(row_to_combo, axis=1)
    return df_base

# ======================================================
# PREP LABEL TOTALS + FILTERS (ONCE)
# ======================================================
label_cols = [c for c in df_clients.columns if c.startswith("Label")]
df_clients["Total"] = df_clients[label_cols].sum(axis=1)

# Reliability filter
df_clients = df_clients[df_clients["Reliability_Score"] >= 0.6].reset_index(drop=True)

# Event rate
df_clients["Normal"]   = df_clients["Label0"]
df_clients["Abnormal"] = df_clients["Total"] - df_clients["Label0"]
df_clients["Event_Rate"] = df_clients["Abnormal"] / df_clients["Total"]

# ======================================================
# FED-MCCS PARAMETERS (SAME AS YOUR CODE)
# ======================================================
TIME_THRESHOLD = 32.0
MODEL_SIZE_MB  = 1.0
BW             = 1.0
LAT            = 0.1
download_time  = MODEL_SIZE_MB / BW + LAT
upload_time    = MODEL_SIZE_MB / BW + LAT

# ======================================================
# FUNCTION — Predict Update Time (NO CHANGE)
# ======================================================
def predict_update_time(client_id):
    hist = df_clients[df_clients["Client_ID"] == client_id]
    X = hist["Total"].values.reshape(-1, 1)
    y = hist["Train_Time(s)"].values

    if len(hist) == 0:
        raise ValueError(f"Client_ID {client_id} not found in df_clients after filtering.")

    if len(hist) == 1:
        slope = y[0] / X[0]
        intercept = 0.0
    else:
        lr = LinearRegression().fit(X, y)
        slope, intercept = lr.coef_[0], lr.intercept_

    cur_total = hist["Total"].iloc[-1]
    return float(slope * cur_total + intercept)

# ======================================================
# RUN Fed-MCCS FOR EACH FILE
# ======================================================
fed_mccs_outputs = {}  # keep outputs in memory for Cell 2

for tag, combos_path in COMBO_FILES.items():
    print(f"\n===== Fed-MCCS Processing: {tag} =====")

    df_base = pd.read_csv(combos_path)
    df_base = ensure_combination_column(df_base)

    results = []
    for combo_str in df_base["Combination"]:
        combo = list(map(int, combo_str.split("_")))

        combo_rows = df_clients[df_clients["Client_ID"].isin(combo)].copy()
        combo_rows = combo_rows.sort_values("Event_Rate", ascending=False)

        theta = 0.0
        for _, row in combo_rows.iterrows():
            predicted_update = predict_update_time(row["Client_ID"])
            total_time = download_time + predicted_update + upload_time
            theta += total_time

        raw_score = 1.0 - (theta / TIME_THRESHOLD)

        results.append({
            "Combination": combo_str,
            "Theta(TimeSum)": round(theta, 3),
            "Score": raw_score,  # raw for now
        })

    df_results = pd.DataFrame(results)

    # ----------------------------
    # SCALE Score to [0,1] (overwrite Score)
    # ----------------------------
    smin = df_results["Score"].min()
    smax = df_results["Score"].max()
    if smax > smin:
        df_results["Score"] = (df_results["Score"] - smin) / (smax - smin)
    else:
        df_results["Score"] = 1.0
    df_results["Score"] = df_results["Score"].round(6)

    # Save + keep
    df_results.to_csv(OUT_PATHS[tag], index=False)
    print(f"✅ Saved: {OUT_PATHS[tag]} | Rows: {len(df_results)}")
    print("Scaled Score min/max:", float(df_results["Score"].min()), float(df_results["Score"].max()))

    fed_mccs_outputs[tag] = df_results

df=pd.read_csv("/content/B_3_FedMCCS_results.csv")
df

df['Score'].describe()

"""**HAR**

"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once here)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 73, "fed_sf": 0.65},
    "B_3": {"acc": 73, "fed_sf": 0.65},
    "C_5": {"acc": 73, "fed_sf": 0.65},
}

# --------------------------------------------------
# Load the SAME combo files again to get Global_Accuracy
# and merge with Fed-SF by Combination (NOT row-wise)
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_sf_outputs[tag].copy()

    # Merge to align scores correctly
    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedSF_Score"})

    # Column check (change here if your file uses a different name)
    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. موجود؟ check column name exactly.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, FedSF>{FED_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (FedSF)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_eval = combo_dfs[tag].merge(
        fed_sf_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedSF_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))

"""**CIFAR10**

"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once here)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 49, "fed_sf": 0.69},
    "B_3": {"acc": 49, "fed_sf": 0.66},
    "C_5": {"acc": 49, "fed_sf": 0.65},
}

# --------------------------------------------------
# Load the SAME combo files again to get Global_Accuracy
# and merge with Fed-SF by Combination (NOT row-wise)
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_sf_outputs[tag].copy()

    # Merge to align scores correctly
    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedSF_Score"})

    # Column check (change here if your file uses a different name)
    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. موجود؟ check column name exactly.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, FedSF>{FED_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (FedSF)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_eval = combo_dfs[tag].merge(
        fed_sf_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedSF_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))



"""**FMNIST**

"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once here)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 83, "fed_sf": 0.50},
    "B_3": {"acc": 73, "fed_sf": 0.50},
    "C_5": {"acc": 73, "fed_sf": 0.50},
}

# --------------------------------------------------
# Load the SAME combo files again to get Global_Accuracy
# and merge with Fed-SF by Combination (NOT row-wise)
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_sf_outputs[tag].copy()

    # Merge to align scores correctly
    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedSF_Score"})

    # Column check (change here if your file uses a different name)
    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. موجود؟ check column name exactly.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, FedSF>{FED_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (FedSF)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    FED_TH = THRESHOLDS[tag]["fed_sf"]

    df_eval = combo_dfs[tag].merge(
        fed_sf_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedSF_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedSF_Score"] > FED_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))



"""**MINIST**

"""

# ===========================
# CELL 2 — Confusion Matrices (1x3 side-by-side) USING THRESHOLD DICT (ACC vs Fed-MCCS)
# ===========================
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt

# --------------------------------------------------
# Thresholds per file (edit once)
# --------------------------------------------------
THRESHOLDS = {
    "A_2": {"acc": 81, "mccs": 0.60},
    "B_3": {"acc": 79, "mccs": 0.49},
    "C_5": {"acc": 80, "mccs": 0.49},
}

# --------------------------------------------------
# Load combo files again to get Global_Accuracy
# and merge with Fed-MCCS scores by Combination
# --------------------------------------------------
combo_dfs = {}
for tag, path in COMBO_FILES.items():
    df_tmp = pd.read_csv(path)
    df_tmp = ensure_combination_column(df_tmp)
    combo_dfs[tag] = df_tmp

# --------------------------------------------------
# Plot 1x3 confusion matrices
# --------------------------------------------------
tags = list(THRESHOLDS.keys())
fig, axes = plt.subplots(1, len(tags), figsize=(18, 5))

if len(tags) == 1:
    axes = [axes]

for ax, tag in zip(axes, tags):
    ACC_TH = THRESHOLDS[tag]["acc"]
    MCCS_TH = THRESHOLDS[tag]["mccs"]

    df_combo = combo_dfs[tag].copy()
    df_score = fed_mccs_outputs[tag].copy()

    df_eval = df_combo.merge(df_score[["Combination", "Score"]], on="Combination", how="left")
    df_eval = df_eval.rename(columns={"Score": "FedMCCS_Score"})

    if "Global_Accuracy" not in df_eval.columns:
        raise ValueError(f"{tag}: 'Global_Accuracy' column not found in combos CSV. Check exact column name.")

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedMCCS_Score"] > MCCS_TH).astype(int)

    cm = confusion_matrix(y_true, y_pred)
    acc = accuracy_score(y_true, y_pred)

    ax.imshow(cm, interpolation="nearest")
    ax.set_title(f"{tag} | ACC>{ACC_TH}, MCCS>{MCCS_TH}\nAccuracy={acc:.4f}")
    ax.set_xlabel("Predicted (Fed-MCCS)")
    ax.set_ylabel("True (Global_Accuracy)")
    ax.set_xticks([0, 1])
    ax.set_yticks([0, 1])
    ax.set_xticklabels(["Not", "Yes"])
    ax.set_yticklabels(["Not", "Yes"])

    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, str(cm[i, j]), ha="center", va="center")

plt.tight_layout()
plt.show()

# --------------------------------------------------
# Optional: print reports
# --------------------------------------------------
for tag in tags:
    ACC_TH = THRESHOLDS[tag]["acc"]
    MCCS_TH = THRESHOLDS[tag]["mccs"]

    df_eval = combo_dfs[tag].merge(
        fed_mccs_outputs[tag][["Combination", "Score"]].rename(columns={"Score": "FedMCCS_Score"}),
        on="Combination",
        how="left"
    )

    y_true = (df_eval["Global_Accuracy"] > ACC_TH).astype(int)
    y_pred = (df_eval["FedMCCS_Score"] > MCCS_TH).astype(int)

    print(f"\n==================== {tag} ====================")
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Accuracy:", round(accuracy_score(y_true, y_pred), 4))
    print(classification_report(y_true, y_pred, digits=4))

import pandas as pd

# =====================================================
# MANUALLY CONSTRUCT DATA (FROM YOUR TABLE)
# =====================================================
data = [

    # ---------------- FEDCS ----------------
    {"Technique": "FedCS", "Dataset": "CIFAR10", "k": 2, "Value": 0.3978},
    {"Technique": "FedCS", "Dataset": "CIFAR10", "k": 3, "Value": 0.4736},
    {"Technique": "FedCS", "Dataset": "CIFAR10", "k": 5, "Value": 0.6248},

    {"Technique": "FedCS", "Dataset": "HAR", "k": 2, "Value": 0.2869},
    {"Technique": "FedCS", "Dataset": "HAR", "k": 3, "Value": 0.2544},
    {"Technique": "FedCS", "Dataset": "HAR", "k": 5, "Value": 0.2447},

    {"Technique": "FedCS", "Dataset": "FMNIST", "k": 2, "Value": 0.3210},
    {"Technique": "FedCS", "Dataset": "FMNIST", "k": 3, "Value": 0.3812},
    {"Technique": "FedCS", "Dataset": "FMNIST", "k": 5, "Value": 0.4890},

    {"Technique": "FedCS", "Dataset": "MNIST", "k": 2, "Value": 0.3677},
    {"Technique": "FedCS", "Dataset": "MNIST", "k": 3, "Value": 0.5177},
    {"Technique": "FedCS", "Dataset": "MNIST", "k": 5, "Value": 0.4979},

    # ---------------- COMPOSABILITY ----------------
    {"Technique": "Composability", "Dataset": "MNIST", "k": 2, "Value": 74.34},
    {"Technique": "Composability", "Dataset": "MNIST", "k": 3, "Value": 72.00},
    {"Technique": "Composability", "Dataset": "MNIST", "k": 5, "Value": 72.96},

    {"Technique": "Composability", "Dataset": "FMNIST", "k": 2, "Value": 71.27},
    {"Technique": "Composability", "Dataset": "FMNIST", "k": 3, "Value": 74.62},
    {"Technique": "Composability", "Dataset": "FMNIST", "k": 5, "Value": 73.28},

    {"Technique": "Composability", "Dataset": "CIFAR10", "k": 2, "Value": 73.37},
    {"Technique": "Composability", "Dataset": "CIFAR10", "k": 3, "Value": 73.49},
    {"Technique": "Composability", "Dataset": "CIFAR10", "k": 5, "Value": 72.39},

    {"Technique": "Composability", "Dataset": "HAR", "k": 2, "Value": 70.69},
    {"Technique": "Composability", "Dataset": "HAR", "k": 3, "Value": 70.89},
    {"Technique": "Composability", "Dataset": "HAR", "k": 5, "Value": 70.12},

    # ---------------- FEDMCS ----------------
    {"Technique": "FedMCS", "Dataset": "CIFAR10", "k": 2, "Value": 0.3978},
    {"Technique": "FedMCS", "Dataset": "CIFAR10", "k": 3, "Value": 0.4736},
    {"Technique": "FedMCS", "Dataset": "CIFAR10", "k": 5, "Value": 0.4558},

    {"Technique": "FedMCS", "Dataset": "HAR", "k": 2, "Value": 0.3622},
    {"Technique": "FedMCS", "Dataset": "HAR", "k": 3, "Value": 0.2633},
    {"Technique": "FedMCS", "Dataset": "HAR", "k": 5, "Value": 0.2406},

    {"Technique": "FedMCS", "Dataset": "FMNIST", "k": 2, "Value": 0.4846},
    {"Technique": "FedMCS", "Dataset": "FMNIST", "k": 3, "Value": 0.4639},
    {"Technique": "FedMCS", "Dataset": "FMNIST", "k": 5, "Value": 0.4675},

    {"Technique": "FedMCS", "Dataset": "MNIST", "k": 2, "Value": 0.4071},
    {"Technique": "FedMCS", "Dataset": "MNIST", "k": 3, "Value": 0.5081},
    {"Technique": "FedMCS", "Dataset": "MNIST", "k": 5, "Value": 0.5488},
]

# =====================================================
# CREATE DATAFRAME
# =====================================================
df = pd.DataFrame(data)

df



"""**Visulizations**
---
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Data from user (FedCS/FedMCS in [0,1], Composability in %)
data = [
    # FedCS
    ("FedCS","CIFAR-10",2,0.3978), ("FedCS","CIFAR-10",3,0.4736), ("FedCS","CIFAR-10",5,0.6248),
    ("FedCS","HAR",2,0.2869), ("FedCS","HAR",3,0.2544), ("FedCS","HAR",5,0.2447),
    ("FedCS","FMNIST",2,0.3210), ("FedCS","FMNIST",3,0.3812), ("FedCS","FMNIST",5,0.4890),
    ("FedCS","MNIST",2,0.3677), ("FedCS","MNIST",3,0.5177), ("FedCS","MNIST",5,0.4979),
    # Composability (already %)
    ("Composability","MNIST",2,74.34), ("Composability","MNIST",3,72.00), ("Composability","MNIST",5,72.96),
    ("Composability","FMNIST",2,71.27), ("Composability","FMNIST",3,74.62), ("Composability","FMNIST",5,73.28),
    ("Composability","CIFAR-10",2,73.37), ("Composability","CIFAR-10",3,73.49), ("Composability","CIFAR-10",5,72.39),
    ("Composability","HAR",2,70.69), ("Composability","HAR",3,70.89), ("Composability","HAR",5,70.12),
    # FedMCS
    ("FedMCS","CIFAR-10",2,0.3978), ("FedMCS","CIFAR-10",3,0.4736), ("FedMCS","CIFAR-10",5,0.4558),
    ("FedMCS","HAR",2,0.3622), ("FedMCS","HAR",3,0.2633), ("FedMCS","HAR",5,0.2406),
    ("FedMCS","FMNIST",2,0.4846), ("FedMCS","FMNIST",3,0.4639), ("FedMCS","FMNIST",5,0.4675),
    ("FedMCS","MNIST",2,0.4071), ("FedMCS","MNIST",3,0.5081), ("FedMCS","MNIST",5,0.5488),
]

df = pd.DataFrame(data, columns=["Technique","Dataset","k","Value"])

# Convert baseline values to percentages so scale matches the example plot
df["Accuracy_%"] = df.apply(lambda r: r["Value"]*100 if r["Technique"] in ["FedCS","FedMCS"] else r["Value"], axis=1)

# Create category labels like MNIST2, MNIST3, MNIST5...
df["Category"] = df["Dataset"].str.replace("-","", regex=False) + "_K" + df["k"].astype(str)

# Order categories by dataset then k
dataset_order = ["MNIST","FMNIST","CIFAR-10","HAR"]
k_order = [2,3,5]
cat_order = [d.replace("-","") + f"_K{k}" for d in dataset_order for k in k_order]

pivot = df.pivot_table(index="Category", columns="Technique", values="Accuracy_%", aggfunc="mean").reindex(cat_order)

# Plot (grouped bars)
techniques = ["FedCS","FedMCS","Composability"]
x = np.arange(len(pivot.index))
bar_w = 0.25

plt.figure(figsize=(16,6))
for i, t in enumerate(techniques):
    plt.bar(x + (i-1)*bar_w, pivot[t].values, width=bar_w, label=t)

plt.xticks(x, pivot.index, rotation=30, ha="right")
plt.ylabel("Accuracy (%)")
plt.xlabel("Service Categories (Dataset + K)")
plt.title("Accuracy Comparison Across Datasets and K")
plt.legend()
plt.grid(axis="y", linestyle="--", alpha=0.4)
plt.tight_layout()
plt.show()

pivot.reset_index().rename_axis(None, axis=1).head()